<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="Looking here or there? Gaze Following in 360-Degree Images">
    <meta name="author" content="Yunhao Li,
                                Wei Shen,
                                Zhongpai Gao,
                                Yucheng Zhu, Guangtao Zhai, Guodong Guo">

    <title>Looking here or there? Gaze Following in 360-Degree Images</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>Looking here or there? Gaze Following in 360-Degree Images</h2>
    <h3>ICCV 2021</h3>
    <hr>
    <p class="authors">
        Yunhao Li</a>,
        Wei Shen</a>,
        Zhongpai Gao</a>,
        Yucheng Zhu</a>,</br>
        Guangtao Zhai</a>,
        Guodong Guo</a></br>
        Shanghai Jiao Tong University
    </p>
    <div class="btn-group" role="group" aria-label="Top menu">
<!--         <a class="btn btn-primary" href="https://arxiv.org/abs/2006.09661">Paper</a>
        <a class="btn btn-primary" href="https://colab.research.google.com/github/vsitzmann/siren/blob/master/explore_siren.ipynb">Colab Notebook</a>
        <a class="btn btn-primary" href="https://dcato98.github.io/playground/#activation=sine">Tensorflow Playground</a>
        <a class="btn btn-primary" href="https://github.com/vsitzmann/siren">Code</a>
        <a class="btn btn-primary" href="https://drive.google.com/drive/u/1/folders/1_iq__37-hw7FJOEUK1tX7mdp8SKB368K">Data</a> -->
    </div>
</div>

<div class="container">
    <div class="section">
	<div class="col-sm">
            <h5></h5>
<!--                 <img src="img/page-example.png"width:25%"> -->
		
		
        </div>
        <hr>
        <p>
<!--             can adding some words -->
        </p>
    </div>

    <div class="section">
        <h2>Abstract</h2>
        <hr>
        <p>
	    Gaze following, i.e., detecting the gaze target of a human subject, in 2D images has become an active topic in computer vision. However, it usually 
	    suffers from the out of frame issue due to the limited field-of-view (FoV) of 2D images. In this paper, we introduce a novel task, gaze following in 
	    360-degree images which provide an omnidirectional FoV and can alleviate the out of frame issue. We collect the first dataset, 
            "GazeFollow360", for this task, containing around 10,000 360-degree 
	    images with complex gaze behaviors under various scenes. Existing 2D gaze following methods suffer from performance degradation in 360-degree images since 
	    they may use the assumption that a gaze target is in the 2D gaze sight line. However, this assumption is no longer true for long-distance gaze behaviors in 
	    360-degree images, due to the distortion brought by sphere-to-plane projection. To address this challenge, 
	    we propose a 3D sight line guided dual-pathway framework, to detect the gaze target within a local region (here) and from a distant region (there), parallelly. 
	    Specifically, the local region is obtained as a 2D cone-shaped field along the 2D projection of the sight line starting at the human subject’s head position, 
	    and the distant region is obtained by searching along the sight line in 3D sphere space. Finally, the location of the gaze target is determined by fusing 
	    the estimations from both the local region and the distant region. Experimental results show that our method achieves significant improvements over 
	    previous 2D gaze following methods on our GazeFollow360 dataset.
        </p>
    </div>

    <div class="section">
        <h2>GazeFollow360 Dataset</h2>
        <hr>
        <p>
	    The dataset is available for free only for research purposes. We greatly welcome emails 
	    about questions or suggestions if you find some confusing things or mistakes. Please email to lyhsjtu@sjtu.edu.cn. 
	    Please cite this paper if you use the dataset.
			
	    Dataset link: Baidudisk  ( https://pan.baidu.com/s/1aTVH6WH3pcz6OysQ4Tmo7g ,passward: njqk)
        </p>
    </div>
			
    <div class="section">
        <h2>Evaluation Protocol for our GazeFollow360 Dataset</h2>
        <hr>
        <p>
	     <b>•Spherical distance</b>: we use the spherical distance, a.k.a., great-circle distance, as our evaluation metric intead. It is the shortest 
	     distance between two points on the surface of a sphere. </br>
			
	     <b>•AUC</b>: we use the Area Under Curve (AUC) criterion to assess a predicted gaze target heatmap. For fair comparsion, all the predicted heatmap
	     are upsample/downsample to a 64*64 heatmap and are compared a heatmap of the same size with kernel size 3 to calculate the AUC score. </br>
	    
        </p>
    </div>

<!--     <div class="section">
        <h2>Paper and Supplementary Material</h2>
        <hr>
        <p>
            [[`ICCV Paper`](https://openaccess.thecvf.com/content/ICCV2021/html/Li_Looking_Here_or_There_Gaze_Following_in_360-Degree_Images_ICCV_2021_paper.html)]
        </p>
    </div> -->
	    	    
    <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
       @inproceedings{li2021looking,
	  title={Looking here or there? gaze following in 360-degree images},
	  author={Li, Yunhao and Shen, Wei and Gao, Zhongpai and Zhu, Yucheng and Zhai, Guangtao and Guo, Guodong},
	  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	  pages={3742--3751},
	  year={2021}
	}


        </div>
    </div>
    <hr>

    <footer>
        <p>Send feedback and questions to lyhsjtu@sjtu.edu.cn</a></p>
    </footer>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
